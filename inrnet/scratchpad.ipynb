{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfae1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, itertools, yaml, kornia, torchvision, sys, copy, math\n",
    "from functools import partial\n",
    "import dill as pickle\n",
    "from importlib import reload\n",
    "osp = os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "nn = torch.nn\n",
    "F = nn.functional\n",
    "import monai.transforms as mtr\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8944308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inrnet import args as args_module\n",
    "from inrnet import inn, experiments, optim, util, losses, models, jobs as job_mgmt\n",
    "from inrnet.data import dataloader\n",
    "from inrnet.experiments import depth\n",
    "import inrnet.inn.functional as inrF\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (4.0, 3.0)\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "rescale_clip = mtr.ScaleIntensityRangePercentiles(lower=1, upper=99, b_min=0, b_max=255, clip=True, dtype=np.uint8)\n",
    "rescale_noclip = mtr.ScaleIntensityRangePercentiles(lower=0, upper=100, b_min=0, b_max=255, clip=False, dtype=np.uint8)\n",
    "rescale_float = mtr.ScaleIntensity()\n",
    "\n",
    "TMP_DIR=osp.expanduser(\"~/code/diffcoord/temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b2ca0",
   "metadata": {},
   "source": [
    "rsync -av --ignore-existing \\\n",
    "clintonw@peppercorn.csail.mit.edu:/data/vision/polina/users/clintonw/code/placenta/results/unetr_00 Downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbadd6f",
   "metadata": {},
   "source": [
    "# interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21871790",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash train.sh inet_nn_train inet_nn_train\n",
    "bash train.sh inet_inn_rand inet_train\n",
    "bash train.sh inet_scr_rand inet_scr_train\n",
    "\n",
    "bash infer.sh i1x_nn inet_val inet_nn_train\n",
    "bash infer.sh i1x_inn inet_val inet_inn_train\n",
    "bash infer.sh i1x_scr inet_val inet_scr_train\n",
    "bash infer.sh i2x_nn in2x_val inet_nn_train\n",
    "bash infer.sh i2x_inn in2x_val inet_inn_train\n",
    "bash infer.sh i2x_scr in2x_val inet_scr_train\n",
    "bash infer.sh ihx_nn inhx_val inet_nn_train\n",
    "bash infer.sh ihx_inn inhx_val inet_inn_train\n",
    "bash infer.sh ihx_scr inhx_val inet_scr_train\n",
    "python infer.py -j=inet_inn_val -c=inet_val -t=inet_inn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb816ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash infer.sh i1x_inn inet_val inet_inn_rand\n",
    "bash infer.sh i1x_scr inet_val inet_scr_rand\n",
    "bash infer.sh i2x_inn in2x_val inet_inn_rand\n",
    "bash infer.sh i2x_scr in2x_val inet_scr_rand\n",
    "bash infer.sh ihx_inn inhx_val inet_inn_rand\n",
    "bash infer.sh ihx_scr inhx_val inet_scr_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ab6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load('/data/vision/polina/users/clintonw/code/diffcoord/temp/upernet_convnext.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98823151",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'decode_head.fpn_bottleneck.'\n",
    "fpn_bot_sd = {k[len(root):]:v for k,v in sd.items() if k.startswith(root)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_bot_sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2491f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "662f81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0.conv.weight', '0.bn.weight', '0.bn.bias', '0.bn.running_mean', '0.bn.running_var', '0.bn.num_batches_tracked', '1.conv.weight', '1.bn.weight', '1.bn.bias', '1.bn.running_mean', '1.bn.running_var', '1.bn.num_batches_tracked', '2.conv.weight', '2.bn.weight', '2.bn.bias', '2.bn.running_mean', '2.bn.running_var', '2.bn.num_batches_tracked'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_fpn_sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f3ebe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 96, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_lateral_sd[f'0.conv.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5204a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0.conv.weight', '0.bn.weight', '0.bn.bias', '0.bn.running_mean', '0.bn.running_var', '0.bn.num_batches_tracked', '1.conv.weight', '1.bn.weight', '1.bn.bias', '1.bn.running_mean', '1.bn.running_var', '1.bn.num_batches_tracked', '2.conv.weight', '2.bn.weight', '2.bn.bias', '2.bn.running_mean', '2.bn.running_var', '2.bn.num_batches_tracked'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_lateral_sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a516977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0.conv.weight', '0.bn.weight', '0.bn.bias', '0.bn.running_mean', '0.bn.running_var', '0.bn.num_batches_tracked', '1.conv.weight', '1.bn.weight', '1.bn.bias', '1.bn.running_mean', '1.bn.running_var', '1.bn.num_batches_tracked', '2.conv.weight', '2.bn.weight', '2.bn.bias', '2.bn.running_mean', '2.bn.running_var', '2.bn.num_batches_tracked'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_fpn_sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"/data/vision/polina/users/clintonw/code/diffcoord/results/inet/results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=3 python train.py -j=inet2 -c=inet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ffec1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59773cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = torch.load(osp.expanduser('~/code/diffcoord/temp/upernet_convnext.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2487ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.Cityscapes(DS_DIR+'/cityscapes',\n",
    "            split='val', mode='coarse', target_type='semantic',\n",
    "            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ce683b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "36317def",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('/data/vision/polina/scratch/clintonw/datasets/cityscapes/gtCoarse/val/frankfurt/frankfurt_000001_080091_gtCoarse_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a176363",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_DIR = \"/data/vision/polina/scratch/clintonw/datasets\"\n",
    "ds = torchvision.datasets.CIFAR10(root=DS_DIR, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90ff5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "coords = util.meshgrid_coords(64,64)\n",
    "#spacing = torch.tensor((4/127,4/127), device=\"cuda\")\n",
    "values = torch.randn(coords.size(0),6, device=coords.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=torch.linspace(128,256,10), y=torch.linspace(.5,.8,10)+torch.randn(10)/8, label=\"qmc\");\n",
    "sns.lineplot(x=torch.linspace(128,256,10), y=torch.linspace(.1,.8,10)+torch.randn(10)/8, label=\"grid\", ax=ax);\n",
    "ax.set_xlabel(\"Number of sample points\");\n",
    "ax.set_ylabel(\"ImageNet top-1 error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b5e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## search python strings\n",
    "import os\n",
    "osp = os.path\n",
    "root = osp.expanduser(\"~/code/diffcoord/inrnet\")\n",
    "query_string = ' INR'\n",
    "for folder, subfolders, files in os.walk(root):\n",
    "    for file in files:\n",
    "        if file.endswith(\".py\"):\n",
    "            path = osp.join(folder, file)\n",
    "            with open(path, 'r') as f:\n",
    "                if query_string in f.read():\n",
    "                    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bdc5c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## inet12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cd748",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from robustness.tools.imagenet_helpers import ImageNetHierarchy, common_superclass_wnid\n",
    "in_path = '/data/vision/polina/scratch/clintonw/datasets/imagenet_pytorch'\n",
    "in_hier = ImageNetHierarchy(in_path, in_path)\n",
    "superclass_wnid = common_superclass_wnid('big_12')\n",
    "class_ranges, label_map = in_hier.get_subclasses(superclass_wnid,\n",
    "                                                 balanced=True)\n",
    "\n",
    "sub_to_super = {}\n",
    "for supercls,subclasses in enumerate(class_ranges):\n",
    "    for subcls in subclasses:\n",
    "        sub_to_super[subcls] = supercls\n",
    "\n",
    "big12path = f\"{DS_DIR}/inrnet/big_12.pkl\"\n",
    "pickle.dump((label_map, class_ranges, sub_to_super), open(big12path, 'wb'))\n",
    "\n",
    "label_to_super = {}\n",
    "for supercls,subclasses in enumerate(class_labels):\n",
    "    for subcls in subclasses:\n",
    "        label_to_super[subcls] = supercls\n",
    "\n",
    "big12path = f\"{DS_DIR}/inrnet/big_12_labels.pkl\"\n",
    "pickle.dump((split_paths_by_cls, class_labels, label_to_super), open(big12path, 'wb'))\n",
    "\n",
    "label = osp.basename(osp.dirname(subpaths[0]))\n",
    "\n",
    "subpaths_by_cls = [[] for _ in range(12)]\n",
    "for path in subpaths:\n",
    "    label = osp.basename(osp.dirname(path))\n",
    "    if label in label_to_super.keys():\n",
    "        subpaths_by_cls[label_to_super[label]].append(path)\n",
    "\n",
    "split_paths_by_cls = {'train':[p[:800] for p in subpaths_by_cls],\n",
    "                     'test':[p[800:] for p in subpaths_by_cls]}\n",
    "\n",
    "for p in subpaths_by_cls:\n",
    "    np.random.shuffle(p)\n",
    "\n",
    "subpaths = open(\"/data/vision/polina/scratch/clintonw/datasets/imagenet_pytorch/val.txt\",\n",
    "            \"r\").read().split('\\n')\n",
    "\n",
    "labels = open(\"/data/vision/polina/scratch/clintonw/datasets/imagenet_pytorch/labels.txt\",\n",
    "            \"r\").read().split('\\n')\n",
    "\n",
    "labels = [l[:l.find(',')] for l in labels[:-1]]\n",
    "\n",
    "class_labels = [np.array(labels)[list(cr)].tolist() for cr in class_ranges]\n",
    "\n",
    "paths = util.glob2('/data/vision/polina/scratch/clintonw/datasets/inrnet/cityscapes/train_*.pt')\n",
    "for p in paths:\n",
    "    weights, seg = torch.load(p)\n",
    "    break\n",
    "\n",
    "from inrnet.models.inrs import siren\n",
    "\n",
    "keys = siren.get_siren_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb82f2",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21213782",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14c4018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffNet-T & 38.0\\% & 34.9\\% & 28.6\\% \\\\\n",
      "INR-tuned (ours) & 7.2\\% & 8.2\\% & 8.0\\% \\\\\n",
      "INR-scratch (ours) & 16.0\\% & 10.8\\% & 8.8\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = osp.expanduser(\"~/code/diffcoord/results\")\n",
    "\n",
    "model_jobs = {'EffNet-T':('i1x_nn', 'i2x_nn', 'ihx_nn'),\n",
    "    'INR-tuned (ours)':('i1x_inn', 'i2x_inn', 'ihx_inn'),\n",
    "    'INR-scratch (ours)':('i1x_scr', 'i2x_scr', 'ihx_scr')}\n",
    "N = 200*12\n",
    "for model,row in model_jobs.items():\n",
    "    rowstr = [model]\n",
    "    for job in row:\n",
    "        path = osp.join(RESULTS_DIR, job, \"stats.pt\")\n",
    "        if not osp.exists(path):\n",
    "            print(f'missing {job} results at {path}')\n",
    "            rowstr.append(\"nan\")\n",
    "        else:\n",
    "            top1, top3 = torch.load(path)\n",
    "            rowstr.append(util.format_float(top3/N*100, n_decimals=1)+r\"\\%\")\n",
    "    print(' & '.join(map(str,rowstr)) + r' \\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2929542",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\"raw_m_rgae\", \"dit_m_rgae\", \"raw_m_caae\", \"dit_m_caae\",\n",
    "        \"raw_m_ipg\", \"dit_m_ipg\", \"raw_m_star\", \"dms_1\"]\n",
    "df = tables.get_results_table()\n",
    "subtable = df.loc[jobs]\n",
    "\n",
    "def latex_format(value, n_decimals=2, bold=False):\n",
    "    if bold:\n",
    "        return (r'$\\bm{{{0:.%df}}}$'%n_decimals).format(value)        \n",
    "    else:\n",
    "        return (r'${0:.%df}$'%n_decimals).format(value)\n",
    "def plus_minus_format(mean, std, n_decimals=2, bold=False):\n",
    "    if bold:\n",
    "        return (r'$\\bm{{{0:.%df}}}$\\scriptsize$\\bm{{\\pm {1:.%df}}}$'%(n_decimals, n_decimals)).format(mean, std)        \n",
    "    else:\n",
    "        return (r'${0:.%df}$\\scriptsize$\\pm {1:.%df}$'%(n_decimals, n_decimals)).format(mean, std)\n",
    "\n",
    "def print_row(name, row, bold=()):\n",
    "    field1 = latex_format(row[\"FID_tuned\"], bold=1 in bold)\n",
    "    field2 = latex_format(row[\"F_{1/8}\"], bold=2 in bold)\n",
    "    field3 = latex_format(row[\"F_8\"], bold=3 in bold)\n",
    "    field4 = plus_minus_format(row[\"age mean error\"], row[\"age error STD\"], bold=4 in bold)\n",
    "    print(\" & \".join([name, field1, field2, field3, field4]) + r\" \\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151b7c9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77b388",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_jobs = {'EffNet-T':('c1x_nn', 'c2x_nn', 'chx_nn'),\n",
    "    'INR-tuned (ours)':('c1x_inn', 'c2x_inn', 'chx_inn'),\n",
    "    'INR-scratch (ours)':('c1x_scr', 'c2x_scr', 'chx_scr')}\n",
    "N = 200*12\n",
    "for model,row in model_jobs.items():\n",
    "    rowstr = [model]\n",
    "    for job in row:\n",
    "        path = osp.join(RESULTS_DIR, job, \"stats.pt\")\n",
    "        if not osp.exists(path):\n",
    "            print(f'missing {job} results at {path}')\n",
    "            rowstr.append(\"nan\")\n",
    "        else:\n",
    "            top1, top3 = torch.load(path)\n",
    "            rowstr.append(util.format_float(top3/N*100, n_decimals=1)+r\"\\%\")\n",
    "    print(' & '.join(map(str,rowstr)) + r' \\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551200d6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c66d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_jobs = {'EffNet-T':('f1x_nn', 'f2x_nn', 'fhx_nn'),\n",
    "    'INR-tuned (ours)':('f1x_inn', 'f2x_inn', 'fhx_inn'),\n",
    "    'INR-scratch (ours)':('f1x_scr', 'f2x_scr', 'fhx_scr')}\n",
    "N = 200*12\n",
    "for model,row in model_jobs.items():\n",
    "    rowstr = [model]\n",
    "    for job in row:\n",
    "        path = osp.join(RESULTS_DIR, job, \"stats.pt\")\n",
    "        if not osp.exists(path):\n",
    "            print(f'missing {job} results at {path}')\n",
    "            rowstr.append(\"nan\")\n",
    "        else:\n",
    "            top1, top3 = torch.load(path)\n",
    "            rowstr.append(util.format_float(top3/N*100, n_decimals=1)+r\"\\%\")\n",
    "    print(' & '.join(map(str,rowstr)) + r' \\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695d4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a2b3ce",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4310bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xy = util.generate_quasirandom_sequence(d=2, n=256)\n",
    "plt.rcParams[\"figure.figsize\"] = (2,1)\n",
    "fig,ax = plt.subplots()\n",
    "ax.scatter(xy[:,0], xy[:,1], s=2, c='k')\n",
    "ax.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5252a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1ae35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kernel = model.features[0][0].weight[3,1].detach()\n",
    "plt.rcParams[\"figure.figsize\"] = (.5,.5)\n",
    "fig,ax = plt.subplots()\n",
    "print(kernel.min().item(), kernel.max().item())\n",
    "ax.imshow(kernel, vmin=-2.9, vmax=2.9);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb67f524",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import RectBivariateSpline as Spline2D\n",
    "K = [2.5,2.5]\n",
    "h,w=3,3\n",
    "bbox = (-K[0]/2, K[0]/2, -K[1]/2, K[1]/2)\n",
    "x,y = (np.linspace(bbox[0]/h*(h-1), bbox[1]/h*(h-1), h),\n",
    "       np.linspace(bbox[2]/w*(w-1), bbox[3]/w*(w-1), w))\n",
    "bs = Spline2D(x,y, kernel, bbox=bbox, kx=2,ky=2, s=0)\n",
    "tx,ty,c = [torch.tensor(z).float() for z in bs.tck]\n",
    "c = c.reshape(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f39f39d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "H = 50\n",
    "xy = util.meshgrid_coords(H,H).cpu()\n",
    "w_oi = []\n",
    "X = xy[:,0].unsqueeze(1)\n",
    "Y = xy[:,1].unsqueeze(1)\n",
    "px = py = 2\n",
    "\n",
    "values, kx = (tx<=X).min(dim=-1)\n",
    "values, ky = (ty<=Y).min(dim=-1)\n",
    "kx -= 1\n",
    "ky -= 1\n",
    "kx[values] = tx.size(-1)-px-2\n",
    "ky[values] = ty.size(-1)-py-2\n",
    "\n",
    "Ctrl = c.view(1, *c.shape[-2:])\n",
    "for z in range(X.size(0)):\n",
    "    D = Ctrl[:, kx[z]-px : kx[z]+1, ky[z]-py : ky[z]+1].clone()\n",
    "\n",
    "    for r in range(1, px + 1):\n",
    "        try:\n",
    "            alphax = (X[z,0] - tx[kx[z]-px+1:kx[z]+1]) / (\n",
    "                tx[2+kx[z]-r:2+kx[z]-r+px] - tx[kx[z]-px+1:kx[z]+1])\n",
    "        except RuntimeError:\n",
    "            print(\"input off the grid\")\n",
    "        for j in range(px, r - 1, -1):\n",
    "            D[:,j] = (1-alphax[j-1]) * D[:,j-1] + alphax[j-1] * D[:,j].clone()\n",
    "\n",
    "    for r in range(1, py + 1):\n",
    "        alphay = (Y[z,0] - ty[ky[z]-py+1:ky[z]+1]) / (\n",
    "            ty[2+ky[z]-r:2+ky[z]-r+py] - ty[ky[z]-py+1:ky[z]+1])\n",
    "        for j in range(py, r-1, -1):\n",
    "            D[:,px,j] = (1-alphay[j-1]) * D[:,px,j-1].clone() + alphay[j-1] * D[:,px,j].clone()\n",
    "\n",
    "    w_oi.append(D[:,px,py])\n",
    "\n",
    "w = torch.stack(w_oi).view(xy.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1cc8ca3d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k = w.reshape(H,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961df22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "print(k.min().item(), k.max().item())\n",
    "ax.imshow(k, vmin=-2.9, vmax=2.9);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ba2b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e00974",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29d940a7",
   "metadata": {},
   "source": [
    "# slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bda67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_len = 118287\n",
    "kitti_len = 80896\n",
    "horse_len = 1067\n",
    "zebra_len = 1334\n",
    "inet_len = 50000\n",
    "in_tr_len = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs/convnext/upernet_convnext_tiny\n",
    "configs/_base_/models/upernet_convnext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,places_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/places/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"place{ix//800}\", \"fit_places\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae78790",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,in_tr_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/imagenet1k_train/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//800}\", \"fit_in_tr\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61f1ee75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh fit_inr.sh inet0 fit_i12 0\n",
      "sh fit_inr.sh inet1 fit_i12 100\n",
      "sh fit_inr.sh inet2 fit_i12 200\n",
      "sh fit_inr.sh inet3 fit_i12 300\n",
      "sh fit_inr.sh inet4 fit_i12 400\n",
      "sh fit_inr.sh inet5 fit_i12 500\n",
      "sh fit_inr.sh inet6 fit_i12 600\n",
      "sh fit_inr.sh inet7 fit_i12 700\n",
      "sh fit_inr.sh inet8 fit_i12 800\n",
      "sh fit_inr.sh inet9 fit_i12 900\n",
      "sh fit_inr.sh inet10 fit_i12 1000\n",
      "sh fit_inr.sh inet11 fit_i12 1100\n",
      "sh fit_inr.sh inet12 fit_i12 1200\n",
      "sh fit_inr.sh inet13 fit_i12 1300\n",
      "sh fit_inr.sh inet14 fit_i12 1400\n",
      "sh fit_inr.sh inet15 fit_i12 1500\n",
      "sh fit_inr.sh inet16 fit_i12 1600\n",
      "sh fit_inr.sh inet17 fit_i12 1700\n",
      "sh fit_inr.sh inet18 fit_i12 1800\n",
      "sh fit_inr.sh inet19 fit_i12 1900\n",
      "sh fit_inr.sh inet20 fit_i12 2000\n",
      "sh fit_inr.sh inet21 fit_i12 2100\n",
      "sh fit_inr.sh inet22 fit_i12 2200\n",
      "sh fit_inr.sh inet23 fit_i12 2300\n",
      "sh fit_inr.sh inet24 fit_i12 2400\n",
      "sh fit_inr.sh inet25 fit_i12 2500\n",
      "sh fit_inr.sh inet26 fit_i12 2600\n",
      "sh fit_inr.sh inet27 fit_i12 2700\n",
      "sh fit_inr.sh inet28 fit_i12 2800\n",
      "sh fit_inr.sh inet29 fit_i12 2900\n",
      "sh fit_inr.sh inet30 fit_i12 3000\n",
      "sh fit_inr.sh inet31 fit_i12 3100\n",
      "sh fit_inr.sh inet32 fit_i12 3200\n",
      "sh fit_inr.sh inet33 fit_i12 3300\n",
      "sh fit_inr.sh inet34 fit_i12 3400\n",
      "sh fit_inr.sh inet35 fit_i12 3500\n",
      "sh fit_inr.sh inet36 fit_i12 3600\n",
      "sh fit_inr.sh inet37 fit_i12 3700\n",
      "sh fit_inr.sh inet38 fit_i12 3800\n",
      "sh fit_inr.sh inet39 fit_i12 3900\n",
      "sh fit_inr.sh inet40 fit_i12 4000\n",
      "sh fit_inr.sh inet41 fit_i12 4100\n",
      "sh fit_inr.sh inet42 fit_i12 4200\n",
      "sh fit_inr.sh inet43 fit_i12 4300\n",
      "sh fit_inr.sh inet44 fit_i12 4400\n",
      "sh fit_inr.sh inet45 fit_i12 4500\n",
      "sh fit_inr.sh inet46 fit_i12 4600\n",
      "sh fit_inr.sh inet47 fit_i12 4700\n",
      "sh fit_inr.sh inet48 fit_i12 4800\n",
      "sh fit_inr.sh inet49 fit_i12 4900\n",
      "sh fit_inr.sh inet50 fit_i12 5000\n",
      "sh fit_inr.sh inet51 fit_i12 5100\n",
      "sh fit_inr.sh inet52 fit_i12 5200\n",
      "sh fit_inr.sh inet53 fit_i12 5300\n",
      "sh fit_inr.sh inet54 fit_i12 5400\n",
      "sh fit_inr.sh inet55 fit_i12 5500\n",
      "sh fit_inr.sh inet56 fit_i12 5600\n",
      "sh fit_inr.sh inet57 fit_i12 5700\n",
      "sh fit_inr.sh inet58 fit_i12 5800\n",
      "sh fit_inr.sh inet59 fit_i12 5900\n",
      "sh fit_inr.sh inet60 fit_i12 6000\n",
      "sh fit_inr.sh inet61 fit_i12 6100\n",
      "sh fit_inr.sh inet62 fit_i12 6200\n",
      "sh fit_inr.sh inet63 fit_i12 6300\n",
      "sh fit_inr.sh inet64 fit_i12 6400\n",
      "sh fit_inr.sh inet65 fit_i12 6500\n",
      "sh fit_inr.sh inet66 fit_i12 6600\n",
      "sh fit_inr.sh inet67 fit_i12 6700\n",
      "sh fit_inr.sh inet68 fit_i12 6800\n",
      "sh fit_inr.sh inet69 fit_i12 6900\n",
      "sh fit_inr.sh inet70 fit_i12 7000\n",
      "sh fit_inr.sh inet71 fit_i12 7100\n",
      "sh fit_inr.sh inet72 fit_i12 7200\n",
      "sh fit_inr.sh inet73 fit_i12 7300\n",
      "sh fit_inr.sh inet74 fit_i12 7400\n",
      "sh fit_inr.sh inet75 fit_i12 7500\n",
      "sh fit_inr.sh inet76 fit_i12 7600\n",
      "sh fit_inr.sh inet77 fit_i12 7700\n",
      "sh fit_inr.sh inet78 fit_i12 7800\n",
      "sh fit_inr.sh inet79 fit_i12 7900\n",
      "sh fit_inr.sh inet80 fit_i12 8000\n",
      "sh fit_inr.sh inet81 fit_i12 8100\n",
      "sh fit_inr.sh inet82 fit_i12 8200\n",
      "sh fit_inr.sh inet83 fit_i12 8300\n",
      "sh fit_inr.sh inet84 fit_i12 8400\n",
      "sh fit_inr.sh inet85 fit_i12 8500\n",
      "sh fit_inr.sh inet86 fit_i12 8600\n",
      "sh fit_inr.sh inet87 fit_i12 8700\n",
      "sh fit_inr.sh inet88 fit_i12 8800\n",
      "sh fit_inr.sh inet89 fit_i12 8900\n",
      "sh fit_inr.sh inet90 fit_i12 9000\n",
      "sh fit_inr.sh inet91 fit_i12 9100\n",
      "sh fit_inr.sh inet92 fit_i12 9200\n",
      "sh fit_inr.sh inet93 fit_i12 9300\n",
      "sh fit_inr.sh inet94 fit_i12 9400\n",
      "sh fit_inr.sh inet95 fit_i12 9500\n",
      "sh fit_inr.sh inet96 fit_i12 9600\n",
      "sh fit_inr.sh inet97 fit_i12 9700\n",
      "sh fit_inr.sh inet98 fit_i12 9800\n",
      "sh fit_inr.sh inet99 fit_i12 9900\n",
      "sh fit_inr.sh inet100 fit_i12 10000\n",
      "sh fit_inr.sh inet101 fit_i12 10100\n",
      "sh fit_inr.sh inet102 fit_i12 10200\n",
      "sh fit_inr.sh inet103 fit_i12 10300\n",
      "sh fit_inr.sh inet104 fit_i12 10400\n",
      "sh fit_inr.sh inet105 fit_i12 10500\n",
      "sh fit_inr.sh inet106 fit_i12 10600\n",
      "sh fit_inr.sh inet107 fit_i12 10700\n",
      "sh fit_inr.sh inet108 fit_i12 10800\n",
      "sh fit_inr.sh inet109 fit_i12 10900\n",
      "sh fit_inr.sh inet110 fit_i12 11000\n",
      "sh fit_inr.sh inet111 fit_i12 11100\n",
      "sh fit_inr.sh inet112 fit_i12 11200\n",
      "sh fit_inr.sh inet113 fit_i12 11300\n",
      "sh fit_inr.sh inet114 fit_i12 11400\n",
      "sh fit_inr.sh inet115 fit_i12 11500\n",
      "sh fit_inr.sh inet116 fit_i12 11600\n",
      "sh fit_inr.sh inet117 fit_i12 11700\n",
      "sh fit_inr.sh inet118 fit_i12 11800\n",
      "sh fit_inr.sh inet119 fit_i12 11900\n"
     ]
    }
   ],
   "source": [
    "for ix in range(0,12000,100):\n",
    "    c,i=ix//1000, ix%1000\n",
    "    if i >= 800:\n",
    "        i-=800\n",
    "        s = 'test'\n",
    "    else:\n",
    "        s='train'\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12_nonorm/{c}/{s}_{i+99}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//100}\", \"fit_i12\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,8189,100):\n",
    "    i = ix\n",
    "    if i < 1020:\n",
    "        s='train'\n",
    "    elif i < 2040:\n",
    "        s='val'\n",
    "        i -= 1020\n",
    "    else:\n",
    "        s='test'\n",
    "        i -= 2040\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/flowers/{s}_{i+50}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"flow{ix//100}\", \"fit_flower\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,3475,100):\n",
    "    i = ix\n",
    "    if i >= 2975:\n",
    "        i -= 2975\n",
    "        s = 'val'\n",
    "    else:\n",
    "        s = 'train'\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/cityscapes/{s}_{i+99}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"city{ix//100}\", \"fit_city\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13166e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,inet_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/imagenet1k_val/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//800}\", \"fit_inet\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6b92f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for ix in range(0,coco_len,1600):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/coco/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"coco{ix//1600}\", \"fit_coco\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b852ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,kitti_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/kitti/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"skit{ix//800}\", \"fit_kitti\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc286a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,zebra_len,128):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/zebra/siren_{ix+15}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"zebra{ix//128}\", \"fit_zebra\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004877cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,horse_len,128):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/horse/siren_{ix+15}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"horse{ix//128}\", \"fit_horse\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef320b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,10000,5000):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/cifar10_test/siren_{ix+999}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"cit{ix//5000}\", \"fit_ciftest\", ix)\n",
    "for ix in range(0,50000,5000):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/cifar10_train/siren_{ix+999}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"cif{ix//5000}\", \"fit_cifar\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"/data/vision/polina/scratch/clintonw/datasets/inrnet/horse2zebra/testA/n02381460_9260.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6392169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/data/vision/polina/scratch/clintonw/datasets/coco/annotations/panoptic_train2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26693f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "osp.exists(f\"/data/vision/polina/users/clintonw/code/diffcoord/temp/kitti/siren_{ix+63}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "201b45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = util.glob2(\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/1/loss_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = util.glob2(\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12_nonorm/0/loss_*\")\n",
    "for p in paths:\n",
    "    print(open(p,'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a3929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
