{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cfae1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, itertools, yaml, kornia, torchvision, sys, copy, math\n",
    "from functools import partial\n",
    "import dill as pickle\n",
    "from importlib import reload\n",
    "osp = os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "nn = torch.nn\n",
    "F = nn.functional\n",
    "import monai.transforms as mtr\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8944308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inrnet import args as args_module\n",
    "from inrnet import inn, experiments, optim, util, losses, models, jobs as job_mgmt\n",
    "from inrnet.data import dataloader\n",
    "from inrnet.experiments import depth\n",
    "import inrnet.inn.functional as inrF\n",
    "from inrnet.models.inrs import siren, rff\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (4.0, 3.0)\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "rescale_clip = mtr.ScaleIntensityRangePercentiles(lower=1, upper=99, b_min=0, b_max=255, clip=True, dtype=np.uint8)\n",
    "rescale_noclip = mtr.ScaleIntensityRangePercentiles(lower=0, upper=100, b_min=0, b_max=255, clip=False, dtype=np.uint8)\n",
    "rescale_float = mtr.ScaleIntensity()\n",
    "DS_DIR = \"/data/vision/polina/scratch/clintonw/datasets\"\n",
    "\n",
    "TMP_DIR=osp.expanduser(\"~/code/diffcoord/temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b2ca0",
   "metadata": {},
   "source": [
    "rsync -av --ignore-existing \\\n",
    "clintonw@peppercorn.csail.mit.edu:/data/vision/polina/users/clintonw/code/placenta/results/unetr_00 Downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbadd6f",
   "metadata": {},
   "source": [
    "# interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7f72a",
   "metadata": {},
   "source": [
    "### cmd line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py -c=seg_nn\n",
    "\n",
    "bash train.sh seg_nn3 seg_nn3\n",
    "bash train.sh seg_i3 seg_i3\n",
    "bash train.sh seg_nn5 seg_nn5\n",
    "bash train.sh seg_i5 seg_i5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash train.sh inet_nn2 inet_nn2\n",
    "bash train.sh inet_nn5 inet_nn5\n",
    "bash train.sh inet_i2 inet_i2\n",
    "bash train.sh inet_i5 inet_i5\n",
    "\n",
    "python infer.py -c=inet_val -t=inet_inn_train\n",
    "bash infer.sh i1x_i2 inet_val inet_i2\n",
    "bash infer.sh i2x_i2 in2x_val inet_i2\n",
    "bash infer.sh i1x_i5 inet_val inet_i5\n",
    "bash infer.sh i2x_i5 in2x_val inet_i5\n",
    "bash infer.sh i1x_nn2 inet_val inet_nn2\n",
    "bash infer.sh i2x_nn2 in2x_val inet_nn2\n",
    "bash infer.sh i1x_nn5 inet_val inet_nn5\n",
    "bash infer.sh i2x_nn5 in2x_val inet_nn5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe019a4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### objectfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f3de0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "python OF_render.py --modality vision \\\n",
    "      --object_file_path /data/vision/polina/scratch/clintonw/datasets/objectfolder/ObjectFolder1-100/1/ObjectFile.pth \\\n",
    "      --vision_test_file_path ~/code/ObjectFolder/demo/vision_1.npy \\\n",
    "      --vision_results_dir ~/code/ObjectFolder/results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1cf5e7f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(-1,1,16, dtype=torch.float, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711460f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['material'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a1440487",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[df['material'].isin(('Ceramic', 'Polycarbonate', 'Wood'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8f537",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for n in df.index:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dff9e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(osp.expanduser('~/code/ObjectFolder/objects.csv'),\n",
    "                 names=['id', 'name', 'volume', 'material', 'url'], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c2948664",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(osp.expanduser('~/code/ObjectFolder/objects300.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9dd2a307",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[:300].to_csv(osp.expanduser('~/code/ObjectFolder/objects300.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2dfc0523",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = np.load(osp.expanduser('~/code/ObjectFolder/demo/vision_1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bd77e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5d2b9eb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(osp.expanduser('~/code/ObjectFolder/demo/vision_1.npy'), out[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617422a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bash train.sh gen_nn4 gen_nn4\n",
    "bash train.sh gen_i4 gen_i4\n",
    "python train.py -c=gen_nn4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7e3cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bash train.sh warp_inn warp_train\n",
    "bash train.sh warp_nn warp_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2766938",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### random fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b9dbf92",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paths = util.glob2('/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/*/test_*.pt')\n",
    "# for path in paths:\n",
    "#     os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d15a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '/data/vision/polina/scratch/clintonw/datasets/inrnet/cityscapes/fine_val_0.pt'\n",
    "sd,seg = torch.load(path)\n",
    "sinr = siren.Siren()\n",
    "sinr.load_state_dict(sd)\n",
    "sinr = siren.to_black_box([sinr])\n",
    "img = sinr.cuda().produce_images(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dc20d343",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/6/val_4.pt'\n",
    "sd = torch.load(path)\n",
    "sinr = siren.Siren()\n",
    "sinr.load_state_dict(sd)\n",
    "sinr = siren.to_black_box([sinr])\n",
    "img = sinr.cuda().produce_images(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a0380ad9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/5/test_0.pt'\n",
    "sd = torch.load(path)\n",
    "inr = rff.RFFNet()\n",
    "inr.load_state_dict(sd)\n",
    "inr = rff.to_black_box([inr])\n",
    "img2 = inr.cuda().produce_images(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a068f08",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import imgviz\n",
    "labelviz_pred = imgviz.label2rgb(seg.max(0).indices)\n",
    "plt.imshow(labelviz_pred); plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a92fcb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "util.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38afa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "util.imshow(torch.cat(((img+1)/2, img2), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f3102aa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = torchvision.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211a09e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "047b7d70",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DS_DIR}/environmental-sound-classification/esc50.csv')\n",
    "classes = np.array(df[['target', 'category']]).tolist()\n",
    "classes = set(['{} {}'.format(c[0], c[1]) for c in classes])\n",
    "classes = np.array([c.split(' ') for c in classes])\n",
    "classes = {k: v for k, v in classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c130b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8aca694",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inrnet.data.audio import utils\n",
    "ESC50 = utils.ESC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089c54c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_splits = [1,2,3,4]\n",
    "test_split = 5\n",
    "\n",
    "shared_params = {'csv_path': f'{DS_DIR}/environmental-sound-classification/esc50.csv',\n",
    "                 'wav_dir': f'{DS_DIR}/environmental-sound-classification/audio',\n",
    "                 'dest_dir': f'{DS_DIR}/environmental-sound-classification/16000',\n",
    "                 'audio_rate': 16000,\n",
    "                 'only_ESC10': True,\n",
    "                 'pad': 0,\n",
    "                 'normalize': True}\n",
    "\n",
    "train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=True,\n",
    "                  **shared_params).batch_gen(16)\n",
    "\n",
    "test_gen = ESC50(folds=[test_split],\n",
    "                 randomize=False,\n",
    "                 strongAugment=False,\n",
    "                 random_crop=False,\n",
    "                 inputLength=4,\n",
    "                 mix=False,\n",
    "                 **shared_params).batch_gen(16)\n",
    "\n",
    "X, Y = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf364dfd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e9e4c7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fc9c43ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sd = torch.load('/data/vision/polina/users/clintonw/code/diffcoord/temp/upernet_deit.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9c289793",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 3, 16, 16])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd['backbone.patch_embed.projection.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e2372141",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['backbone.cls_token', 'backbone.pos_embed', 'backbone.patch_embed.projection.weight', 'backbone.patch_embed.projection.bias', 'backbone.layers.0.ln1.weight', 'backbone.layers.0.ln1.bias', 'backbone.layers.0.attn.attn.in_proj_weight', 'backbone.layers.0.attn.attn.in_proj_bias', 'backbone.layers.0.attn.attn.out_proj.weight', 'backbone.layers.0.attn.attn.out_proj.bias', 'backbone.layers.0.ln2.weight', 'backbone.layers.0.ln2.bias', 'backbone.layers.0.ffn.layers.0.0.weight', 'backbone.layers.0.ffn.layers.0.0.bias', 'backbone.layers.0.ffn.layers.1.weight', 'backbone.layers.0.ffn.layers.1.bias', 'backbone.layers.1.ln1.weight', 'backbone.layers.1.ln1.bias', 'backbone.layers.1.attn.attn.in_proj_weight', 'backbone.layers.1.attn.attn.in_proj_bias', 'backbone.layers.1.attn.attn.out_proj.weight', 'backbone.layers.1.attn.attn.out_proj.bias', 'backbone.layers.1.ln2.weight', 'backbone.layers.1.ln2.bias', 'backbone.layers.1.ffn.layers.0.0.weight', 'backbone.layers.1.ffn.layers.0.0.bias', 'backbone.layers.1.ffn.layers.1.weight', 'backbone.layers.1.ffn.layers.1.bias', 'backbone.layers.2.ln1.weight', 'backbone.layers.2.ln1.bias', 'backbone.layers.2.attn.attn.in_proj_weight', 'backbone.layers.2.attn.attn.in_proj_bias', 'backbone.layers.2.attn.attn.out_proj.weight', 'backbone.layers.2.attn.attn.out_proj.bias', 'backbone.layers.2.ln2.weight', 'backbone.layers.2.ln2.bias', 'backbone.layers.2.ffn.layers.0.0.weight', 'backbone.layers.2.ffn.layers.0.0.bias', 'backbone.layers.2.ffn.layers.1.weight', 'backbone.layers.2.ffn.layers.1.bias', 'backbone.layers.3.ln1.weight', 'backbone.layers.3.ln1.bias', 'backbone.layers.3.attn.attn.in_proj_weight', 'backbone.layers.3.attn.attn.in_proj_bias', 'backbone.layers.3.attn.attn.out_proj.weight', 'backbone.layers.3.attn.attn.out_proj.bias', 'backbone.layers.3.ln2.weight', 'backbone.layers.3.ln2.bias', 'backbone.layers.3.ffn.layers.0.0.weight', 'backbone.layers.3.ffn.layers.0.0.bias', 'backbone.layers.3.ffn.layers.1.weight', 'backbone.layers.3.ffn.layers.1.bias', 'backbone.layers.4.ln1.weight', 'backbone.layers.4.ln1.bias', 'backbone.layers.4.attn.attn.in_proj_weight', 'backbone.layers.4.attn.attn.in_proj_bias', 'backbone.layers.4.attn.attn.out_proj.weight', 'backbone.layers.4.attn.attn.out_proj.bias', 'backbone.layers.4.ln2.weight', 'backbone.layers.4.ln2.bias', 'backbone.layers.4.ffn.layers.0.0.weight', 'backbone.layers.4.ffn.layers.0.0.bias', 'backbone.layers.4.ffn.layers.1.weight', 'backbone.layers.4.ffn.layers.1.bias', 'backbone.layers.5.ln1.weight', 'backbone.layers.5.ln1.bias', 'backbone.layers.5.attn.attn.in_proj_weight', 'backbone.layers.5.attn.attn.in_proj_bias', 'backbone.layers.5.attn.attn.out_proj.weight', 'backbone.layers.5.attn.attn.out_proj.bias', 'backbone.layers.5.ln2.weight', 'backbone.layers.5.ln2.bias', 'backbone.layers.5.ffn.layers.0.0.weight', 'backbone.layers.5.ffn.layers.0.0.bias', 'backbone.layers.5.ffn.layers.1.weight', 'backbone.layers.5.ffn.layers.1.bias', 'backbone.layers.6.ln1.weight', 'backbone.layers.6.ln1.bias', 'backbone.layers.6.attn.attn.in_proj_weight', 'backbone.layers.6.attn.attn.in_proj_bias', 'backbone.layers.6.attn.attn.out_proj.weight', 'backbone.layers.6.attn.attn.out_proj.bias', 'backbone.layers.6.ln2.weight', 'backbone.layers.6.ln2.bias', 'backbone.layers.6.ffn.layers.0.0.weight', 'backbone.layers.6.ffn.layers.0.0.bias', 'backbone.layers.6.ffn.layers.1.weight', 'backbone.layers.6.ffn.layers.1.bias', 'backbone.layers.7.ln1.weight', 'backbone.layers.7.ln1.bias', 'backbone.layers.7.attn.attn.in_proj_weight', 'backbone.layers.7.attn.attn.in_proj_bias', 'backbone.layers.7.attn.attn.out_proj.weight', 'backbone.layers.7.attn.attn.out_proj.bias', 'backbone.layers.7.ln2.weight', 'backbone.layers.7.ln2.bias', 'backbone.layers.7.ffn.layers.0.0.weight', 'backbone.layers.7.ffn.layers.0.0.bias', 'backbone.layers.7.ffn.layers.1.weight', 'backbone.layers.7.ffn.layers.1.bias', 'backbone.layers.8.ln1.weight', 'backbone.layers.8.ln1.bias', 'backbone.layers.8.attn.attn.in_proj_weight', 'backbone.layers.8.attn.attn.in_proj_bias', 'backbone.layers.8.attn.attn.out_proj.weight', 'backbone.layers.8.attn.attn.out_proj.bias', 'backbone.layers.8.ln2.weight', 'backbone.layers.8.ln2.bias', 'backbone.layers.8.ffn.layers.0.0.weight', 'backbone.layers.8.ffn.layers.0.0.bias', 'backbone.layers.8.ffn.layers.1.weight', 'backbone.layers.8.ffn.layers.1.bias', 'backbone.layers.9.ln1.weight', 'backbone.layers.9.ln1.bias', 'backbone.layers.9.attn.attn.in_proj_weight', 'backbone.layers.9.attn.attn.in_proj_bias', 'backbone.layers.9.attn.attn.out_proj.weight', 'backbone.layers.9.attn.attn.out_proj.bias', 'backbone.layers.9.ln2.weight', 'backbone.layers.9.ln2.bias', 'backbone.layers.9.ffn.layers.0.0.weight', 'backbone.layers.9.ffn.layers.0.0.bias', 'backbone.layers.9.ffn.layers.1.weight', 'backbone.layers.9.ffn.layers.1.bias', 'backbone.layers.10.ln1.weight', 'backbone.layers.10.ln1.bias', 'backbone.layers.10.attn.attn.in_proj_weight', 'backbone.layers.10.attn.attn.in_proj_bias', 'backbone.layers.10.attn.attn.out_proj.weight', 'backbone.layers.10.attn.attn.out_proj.bias', 'backbone.layers.10.ln2.weight', 'backbone.layers.10.ln2.bias', 'backbone.layers.10.ffn.layers.0.0.weight', 'backbone.layers.10.ffn.layers.0.0.bias', 'backbone.layers.10.ffn.layers.1.weight', 'backbone.layers.10.ffn.layers.1.bias', 'backbone.layers.11.ln1.weight', 'backbone.layers.11.ln1.bias', 'backbone.layers.11.attn.attn.in_proj_weight', 'backbone.layers.11.attn.attn.in_proj_bias', 'backbone.layers.11.attn.attn.out_proj.weight', 'backbone.layers.11.attn.attn.out_proj.bias', 'backbone.layers.11.ln2.weight', 'backbone.layers.11.ln2.bias', 'backbone.layers.11.ffn.layers.0.0.weight', 'backbone.layers.11.ffn.layers.0.0.bias', 'backbone.layers.11.ffn.layers.1.weight', 'backbone.layers.11.ffn.layers.1.bias', 'decode_head.conv_seg.weight', 'decode_head.conv_seg.bias', 'decode_head.psp_modules.0.1.conv.weight', 'decode_head.psp_modules.0.1.bn.weight', 'decode_head.psp_modules.0.1.bn.bias', 'decode_head.psp_modules.0.1.bn.running_mean', 'decode_head.psp_modules.0.1.bn.running_var', 'decode_head.psp_modules.0.1.bn.num_batches_tracked', 'decode_head.psp_modules.1.1.conv.weight', 'decode_head.psp_modules.1.1.bn.weight', 'decode_head.psp_modules.1.1.bn.bias', 'decode_head.psp_modules.1.1.bn.running_mean', 'decode_head.psp_modules.1.1.bn.running_var', 'decode_head.psp_modules.1.1.bn.num_batches_tracked', 'decode_head.psp_modules.2.1.conv.weight', 'decode_head.psp_modules.2.1.bn.weight', 'decode_head.psp_modules.2.1.bn.bias', 'decode_head.psp_modules.2.1.bn.running_mean', 'decode_head.psp_modules.2.1.bn.running_var', 'decode_head.psp_modules.2.1.bn.num_batches_tracked', 'decode_head.psp_modules.3.1.conv.weight', 'decode_head.psp_modules.3.1.bn.weight', 'decode_head.psp_modules.3.1.bn.bias', 'decode_head.psp_modules.3.1.bn.running_mean', 'decode_head.psp_modules.3.1.bn.running_var', 'decode_head.psp_modules.3.1.bn.num_batches_tracked', 'decode_head.bottleneck.conv.weight', 'decode_head.bottleneck.bn.weight', 'decode_head.bottleneck.bn.bias', 'decode_head.bottleneck.bn.running_mean', 'decode_head.bottleneck.bn.running_var', 'decode_head.bottleneck.bn.num_batches_tracked', 'decode_head.lateral_convs.0.conv.weight', 'decode_head.lateral_convs.0.bn.weight', 'decode_head.lateral_convs.0.bn.bias', 'decode_head.lateral_convs.0.bn.running_mean', 'decode_head.lateral_convs.0.bn.running_var', 'decode_head.lateral_convs.0.bn.num_batches_tracked', 'decode_head.lateral_convs.1.conv.weight', 'decode_head.lateral_convs.1.bn.weight', 'decode_head.lateral_convs.1.bn.bias', 'decode_head.lateral_convs.1.bn.running_mean', 'decode_head.lateral_convs.1.bn.running_var', 'decode_head.lateral_convs.1.bn.num_batches_tracked', 'decode_head.lateral_convs.2.conv.weight', 'decode_head.lateral_convs.2.bn.weight', 'decode_head.lateral_convs.2.bn.bias', 'decode_head.lateral_convs.2.bn.running_mean', 'decode_head.lateral_convs.2.bn.running_var', 'decode_head.lateral_convs.2.bn.num_batches_tracked', 'decode_head.fpn_convs.0.conv.weight', 'decode_head.fpn_convs.0.bn.weight', 'decode_head.fpn_convs.0.bn.bias', 'decode_head.fpn_convs.0.bn.running_mean', 'decode_head.fpn_convs.0.bn.running_var', 'decode_head.fpn_convs.0.bn.num_batches_tracked', 'decode_head.fpn_convs.1.conv.weight', 'decode_head.fpn_convs.1.bn.weight', 'decode_head.fpn_convs.1.bn.bias', 'decode_head.fpn_convs.1.bn.running_mean', 'decode_head.fpn_convs.1.bn.running_var', 'decode_head.fpn_convs.1.bn.num_batches_tracked', 'decode_head.fpn_convs.2.conv.weight', 'decode_head.fpn_convs.2.bn.weight', 'decode_head.fpn_convs.2.bn.bias', 'decode_head.fpn_convs.2.bn.running_mean', 'decode_head.fpn_convs.2.bn.running_var', 'decode_head.fpn_convs.2.bn.num_batches_tracked', 'decode_head.fpn_bottleneck.conv.weight', 'decode_head.fpn_bottleneck.bn.weight', 'decode_head.fpn_bottleneck.bn.bias', 'decode_head.fpn_bottleneck.bn.running_mean', 'decode_head.fpn_bottleneck.bn.running_var', 'decode_head.fpn_bottleneck.bn.num_batches_tracked', 'auxiliary_head.conv_seg.weight', 'auxiliary_head.conv_seg.bias', 'auxiliary_head.convs.0.conv.weight', 'auxiliary_head.convs.0.bn.weight', 'auxiliary_head.convs.0.bn.bias', 'auxiliary_head.convs.0.bn.running_mean', 'auxiliary_head.convs.0.bn.running_var', 'auxiliary_head.convs.0.bn.num_batches_tracked'])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b7a0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b1136",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0e47d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beaa6594",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### fashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1106d2de",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = torchvision.datasets.FashionMNIST(root=DS_DIR, train=True, transform=transforms.ToTensor())\n",
    "len(ds)\n",
    "#inr = siren.Siren(out_channels=1, C=64, first_omega_0=20, hidden_omega_0=20)\n",
    "# xy = util.meshgrid_coords(28,28, c2f=False)\n",
    "# r = xy.norm(dim=-1)\n",
    "# torch.sin(theta)\n",
    "# maxr_theta = min()\n",
    "# theta = torch.atan2(xy[:,1], xy[:,0])\n",
    "# theta.max()\n",
    "# plt.imshow(ds[0][0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f45a6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6e4d742e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sd = torch.load('/data/vision/polina/users/clintonw/code/diffcoord/temp/wgan.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b838a0b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base = torchvision.models.efficientnet_b0(pretrained=False, device='cuda')\n",
    "optim = torch.optim.Adam(base.parameters())\n",
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcbed6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=3 python train.py -j=inet2 -c=inet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ffec1",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59773cbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base = torch.load(osp.expanduser('~/code/diffcoord/temp/upernet_convnext.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "36317def",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread('/data/vision/polina/scratch/clintonw/datasets/cityscapes/gtCoarse/val/frankfurt/frankfurt_000001_080091_gtCoarse_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91f4d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a176363",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DS_DIR = \"/data/vision/polina/scratch/clintonw/datasets\"\n",
    "ds = torchvision.datasets.CIFAR10(root=DS_DIR, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90ff5d79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "coords = util.meshgrid_coords(64,64)\n",
    "#spacing = torch.tensor((4/127,4/127), device=\"cuda\")\n",
    "values = torch.randn(coords.size(0),6, device=coords.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a6cd22e4",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/users/clintonw/code/diffcoord/inrnet/inn/qmc.py\n",
      "/data/vision/polina/users/clintonw/code/diffcoord/inrnet/data/oasis.py\n",
      "/data/vision/polina/users/clintonw/code/diffcoord/inrnet/models/ddpm.py\n",
      "/data/vision/polina/users/clintonw/code/diffcoord/inrnet/experiments/segment.py\n",
      "/data/vision/polina/users/clintonw/code/diffcoord/inrnet/experiments/generate.py\n"
     ]
    }
   ],
   "source": [
    "## search python strings\n",
    "import os\n",
    "osp = os.path\n",
    "root = osp.expanduser(\"~/code/diffcoord/inrnet\")\n",
    "query_string = \"interpolate(\"\n",
    "for folder, subfolders, files in os.walk(root):\n",
    "    for file in files:\n",
    "        if file.endswith(\".py\"):\n",
    "            path = osp.join(folder, file)\n",
    "            with open(path, 'r') as f:\n",
    "                if query_string in f.read():\n",
    "                    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f97c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d0a8ff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "be5516b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sympy import sin, cos, tan, exp, log, integrate\n",
    "from sympy.abc import a,b,c,n,m,x,y\n",
    "from sympy import Point, Polygon\n",
    "from sympy.integrals.intpoly import polytope_integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7009a71e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sympy.functions.special import polynomials, spherical_harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "80b1e244",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "function = (3*polynomials.legendre(2, x)-2*polynomials.legendre(1, x) - 1) * \\\n",
    "    (.6*polynomials.legendre(4, y)-polynomials.legendre(1, y)+1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98793e74",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ea1805dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "polygon = Polygon(Point(0, 0), Point(0, 1), Point(1, 1), Point(1, 0))\n",
    "# polys = [1, x, y, x*y, x**2*y, x*y**2]\n",
    "# expr = x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0ece5d14",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{NaN}$"
      ],
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polytope_integrate(polygon, expr=function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4fd10b19",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1}{4}$"
      ],
      "text/plain": [
       "1/4"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polytope_integrate(polygon, expr=expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6a7fb1fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, x: 1/2, y: 1/2, x*y: 1/4, x**2*y: 1/6, x*y**2: 1/6}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polytope_integrate(polygon, polys, max_degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ada89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92bdc5c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### inet12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2628a836",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inrnet.models.inrs import siren\n",
    "keys = siren.get_siren_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e1e98b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from robustness.tools.imagenet_helpers import ImageNetHierarchy, common_superclass_wnid\n",
    "in_path = '/data/vision/polina/scratch/clintonw/datasets/imagenet_pytorch'\n",
    "in_hier = ImageNetHierarchy(in_path, in_path)\n",
    "superclass_wnid = common_superclass_wnid('big_12')\n",
    "class_ranges, label_map = in_hier.get_subclasses(superclass_wnid,\n",
    "                                                 balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d8a2b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subpaths = open(\"/data/vision/polina/scratch/clintonw/datasets/imagenet_pytorch/train.txt\",\n",
    "            \"r\").read().split('\\n')\n",
    "labels = open(\"/data/vision/polina/scratch/clintonw/datasets/imagenet_pytorch/labels.txt\",\n",
    "            \"r\").read().split('\\n')\n",
    "labels = [l[:l.find(',')] for l in labels[:-1]]\n",
    "class_labels = [np.array(labels)[list(cr)].tolist() for cr in class_ranges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c85014",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub_to_super = {}\n",
    "for supercls,subclasses in enumerate(class_ranges):\n",
    "    for subcls in subclasses:\n",
    "        sub_to_super[subcls] = supercls\n",
    "\n",
    "# big12path = f\"{DS_DIR}/inrnet/big_12.pkl\"\n",
    "# pickle.dump((label_map, class_ranges, sub_to_super), open(big12path, 'wb'))\n",
    "# label_map, class_ranges, sub_to_super = pickle.load(open(big12path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9070c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label_to_super = {}\n",
    "for supercls,subclasses in enumerate(class_labels):\n",
    "    for subcls in subclasses:\n",
    "        label_to_super[subcls] = supercls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7405f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = 800\n",
    "subpaths_by_cls = [[] for _ in range(12)]\n",
    "for path in subpaths:\n",
    "    label = osp.basename(osp.dirname(path))\n",
    "    if label in label_to_super.keys():\n",
    "        subpaths_by_cls[label_to_super[label]].append(path)\n",
    "\n",
    "for p in subpaths_by_cls:\n",
    "    np.random.shuffle(p)\n",
    "\n",
    "split_paths_by_cls = {'train':[p[:N] for p in subpaths_by_cls],\n",
    "                     'test':[p[N:] for p in subpaths_by_cls]}\n",
    "\n",
    "# big12path = f\"{DS_DIR}/inrnet/big_12_labels.pkl\"\n",
    "# pickle.dump((split_paths_by_cls, class_labels, label_to_super), open(big12path, 'wb'))\n",
    "# split_paths_by_cls, class_labels, label_to_super = pickle.load(open(big12path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70d73b3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subpaths_by_cls = [[] for _ in range(12)]\n",
    "for path in subpaths:\n",
    "    label = osp.basename(osp.dirname(path))\n",
    "    if label in label_to_super.keys():\n",
    "        subpaths_by_cls[label_to_super[label]].append(path)\n",
    "\n",
    "for p in subpaths_by_cls:\n",
    "    np.random.shuffle(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d774b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = 23400\n",
    "subpaths_by_cls = [p[:N] for p in subpaths_by_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "691a0c49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "big12path = f\"{DS_DIR}/inrnet/big_12_extra.pkl\"\n",
    "pickle.dump(subpaths_by_cls, open(big12path, 'wb'))\n",
    "# subpaths_by_cls = pickle.load(open(big12path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba01dc2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paths = util.glob2('/data/vision/polina/scratch/clintonw/datasets/inrnet/cityscapes/train_*.pt')\n",
    "for p in paths:\n",
    "    weights, seg = torch.load(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb82f2",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21213782",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e4d63943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-layer CNN & 66.2\\% & 62.5\\% \\\\\n",
      "INR-2 (ours) & 41.9\\% & 39.1\\% \\\\\n",
      "\\hline\n",
      "5-layer CNN & 68.2\\% & 62.1\\% \\\\\n",
      "INR-5 (ours) & 48.1\\% & 45.4\\% \\\\\n",
      "\\hline\n",
      "EfficientNet \\cite{efficientnet} & 66.4\\% & 59.8\\% \\\\\n",
      "INR-ft (ours) & 48.1\\% & 40.5\\% \\\\\n",
      "\\hline\n",
      "INR-mlp (ours) & 32.4\\% & 25.2\\% \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = osp.expanduser(\"~/code/diffcoord/results\")\n",
    "\n",
    "model_jobs = {\n",
    "    '2-layer CNN':('i1x_nn2', 'i2x_nn2'),\n",
    "    'INR-2 (ours)':('i1x_i2', 'i2x_i2'),\n",
    "    '5-layer CNN':('i1x_nn5', 'i2x_nn5'),\n",
    "    'INR-5 (ours)':('i1x_i5', 'i2x_i5'),\n",
    "    'EfficientNet \\cite{efficientnet}':('i1x_nn', 'i2x_nn'),\n",
    "    'INR-ft (ours)':('i1x_inn', 'i2x_inn'),\n",
    "    'INR-mlp (ours)':('i1x_mlp', 'i2x_mlp'),\n",
    "}\n",
    "N = 200*12\n",
    "for model,row in model_jobs.items():\n",
    "    rowstr = [model]\n",
    "    for job in row:\n",
    "        path = osp.join(RESULTS_DIR, job, \"stats.pt\")\n",
    "        if not osp.exists(path):\n",
    "            print(f'missing {job} results at {path}')\n",
    "            rowstr.append(\"nan\")\n",
    "        else:\n",
    "            top1, top3 = torch.load(path)\n",
    "            rowstr.append(util.format_float(top3/N*100, n_decimals=1)+r\"\\%\")\n",
    "    print(' & '.join(map(str,rowstr)) + r' \\\\')\n",
    "    if model.endswith('ours)'):\n",
    "        print(r'\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2929542",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\"raw_m_rgae\", \"dit_m_rgae\", \"raw_m_caae\", \"dit_m_caae\",\n",
    "        \"raw_m_ipg\", \"dit_m_ipg\", \"raw_m_star\", \"dms_1\"]\n",
    "df = tables.get_results_table()\n",
    "subtable = df.loc[jobs]\n",
    "\n",
    "def latex_format(value, n_decimals=2, bold=False):\n",
    "    if bold:\n",
    "        return (r'$\\bm{{{0:.%df}}}$'%n_decimals).format(value)        \n",
    "    else:\n",
    "        return (r'${0:.%df}$'%n_decimals).format(value)\n",
    "def plus_minus_format(mean, std, n_decimals=2, bold=False):\n",
    "    if bold:\n",
    "        return (r'$\\bm{{{0:.%df}}}$\\scriptsize$\\bm{{\\pm {1:.%df}}}$'%(n_decimals, n_decimals)).format(mean, std)        \n",
    "    else:\n",
    "        return (r'${0:.%df}$\\scriptsize$\\pm {1:.%df}$'%(n_decimals, n_decimals)).format(mean, std)\n",
    "\n",
    "def print_row(name, row, bold=()):\n",
    "    field1 = latex_format(row[\"FID_tuned\"], bold=1 in bold)\n",
    "    field2 = latex_format(row[\"F_{1/8}\"], bold=2 in bold)\n",
    "    field3 = latex_format(row[\"F_8\"], bold=3 in bold)\n",
    "    field4 = plus_minus_format(row[\"age mean error\"], row[\"age error STD\"], bold=4 in bold)\n",
    "    print(\" & \".join([name, field1, field2, field3, field4]) + r\" \\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151b7c9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77b388",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_jobs = {'EffNet-T':('c1x_nn', 'c2x_nn', 'chx_nn'),\n",
    "    'INR-tuned (ours)':('c1x_inn', 'c2x_inn', 'chx_inn'),\n",
    "    'INR-scratch (ours)':('c1x_scr', 'c2x_scr', 'chx_scr')}\n",
    "N = 200*12\n",
    "for model,row in model_jobs.items():\n",
    "    rowstr = [model]\n",
    "    for job in row:\n",
    "        path = osp.join(RESULTS_DIR, job, \"stats.pt\")\n",
    "        if not osp.exists(path):\n",
    "            print(f'missing {job} results at {path}')\n",
    "            rowstr.append(\"nan\")\n",
    "        else:\n",
    "            top1, top3 = torch.load(path)\n",
    "            rowstr.append(util.format_float(top3/N*100, n_decimals=1)+r\"\\%\")\n",
    "    print(' & '.join(map(str,rowstr)) + r' \\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551200d6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c66d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_jobs = {'EffNet-T':('f1x_nn', 'f2x_nn', 'fhx_nn'),\n",
    "    'INR-tuned (ours)':('f1x_inn', 'f2x_inn', 'fhx_inn'),\n",
    "    'INR-scratch (ours)':('f1x_scr', 'f2x_scr', 'fhx_scr')}\n",
    "N = 200*12\n",
    "for model,row in model_jobs.items():\n",
    "    rowstr = [model]\n",
    "    for job in row:\n",
    "        path = osp.join(RESULTS_DIR, job, \"stats.pt\")\n",
    "        if not osp.exists(path):\n",
    "            print(f'missing {job} results at {path}')\n",
    "            rowstr.append(\"nan\")\n",
    "        else:\n",
    "            top1, top3 = torch.load(path)\n",
    "            rowstr.append(util.format_float(top3/N*100, n_decimals=1)+r\"\\%\")\n",
    "    print(' & '.join(map(str,rowstr)) + r' \\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695d4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a2b3ce",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Figs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29f095",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## for framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4310bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xy = util.generate_quasirandom_sequence(d=2, n=256)\n",
    "plt.rcParams[\"figure.figsize\"] = (2,1)\n",
    "fig,ax = plt.subplots()\n",
    "ax.scatter(xy[:,0], xy[:,1], s=2, c='k')\n",
    "ax.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5252a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1ae35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kernel = model.features[0][0].weight[3,1].detach()\n",
    "plt.rcParams[\"figure.figsize\"] = (.5,.5)\n",
    "fig,ax = plt.subplots()\n",
    "print(kernel.min().item(), kernel.max().item())\n",
    "ax.imshow(kernel, vmin=-2.9, vmax=2.9);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb67f524",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import RectBivariateSpline as Spline2D\n",
    "K = [2.5,2.5]\n",
    "h,w=3,3\n",
    "bbox = (-K[0]/2, K[0]/2, -K[1]/2, K[1]/2)\n",
    "x,y = (np.linspace(bbox[0]/h*(h-1), bbox[1]/h*(h-1), h),\n",
    "       np.linspace(bbox[2]/w*(w-1), bbox[3]/w*(w-1), w))\n",
    "bs = Spline2D(x,y, kernel, bbox=bbox, kx=2,ky=2, s=0)\n",
    "tx,ty,c = [torch.tensor(z).float() for z in bs.tck]\n",
    "c = c.reshape(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f39f39d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "H = 50\n",
    "xy = util.meshgrid_coords(H,H).cpu()\n",
    "w_oi = []\n",
    "X = xy[:,0].unsqueeze(1)\n",
    "Y = xy[:,1].unsqueeze(1)\n",
    "px = py = 2\n",
    "\n",
    "values, kx = (tx<=X).min(dim=-1)\n",
    "values, ky = (ty<=Y).min(dim=-1)\n",
    "kx -= 1\n",
    "ky -= 1\n",
    "kx[values] = tx.size(-1)-px-2\n",
    "ky[values] = ty.size(-1)-py-2\n",
    "\n",
    "Ctrl = c.view(1, *c.shape[-2:])\n",
    "for z in range(X.size(0)):\n",
    "    D = Ctrl[:, kx[z]-px : kx[z]+1, ky[z]-py : ky[z]+1].clone()\n",
    "\n",
    "    for r in range(1, px + 1):\n",
    "        try:\n",
    "            alphax = (X[z,0] - tx[kx[z]-px+1:kx[z]+1]) / (\n",
    "                tx[2+kx[z]-r:2+kx[z]-r+px] - tx[kx[z]-px+1:kx[z]+1])\n",
    "        except RuntimeError:\n",
    "            print(\"input off the grid\")\n",
    "        for j in range(px, r - 1, -1):\n",
    "            D[:,j] = (1-alphax[j-1]) * D[:,j-1] + alphax[j-1] * D[:,j].clone()\n",
    "\n",
    "    for r in range(1, py + 1):\n",
    "        alphay = (Y[z,0] - ty[ky[z]-py+1:ky[z]+1]) / (\n",
    "            ty[2+ky[z]-r:2+ky[z]-r+py] - ty[ky[z]-py+1:ky[z]+1])\n",
    "        for j in range(py, r-1, -1):\n",
    "            D[:,px,j] = (1-alphay[j-1]) * D[:,px,j-1].clone() + alphay[j-1] * D[:,px,j].clone()\n",
    "\n",
    "    w_oi.append(D[:,px,py])\n",
    "\n",
    "w = torch.stack(w_oi).view(xy.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1cc8ca3d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k = w.reshape(H,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961df22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "print(k.min().item(), k.max().item())\n",
    "ax.imshow(k, vmin=-2.9, vmax=2.9);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ba2b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aed6db6b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2e298",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inrnet.experiments import classify\n",
    "classify.analyze_change_resolution_grid_vs_qmc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe1c43",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=torch.linspace(128,256,10), y=torch.linspace(.5,.8,10)+torch.randn(10)/8, label=\"qmc\");\n",
    "sns.lineplot(x=torch.linspace(128,256,10), y=torch.linspace(.1,.8,10)+torch.randn(10)/8, label=\"grid\", ax=ax);\n",
    "ax.set_xlabel(\"Number of sample points\");\n",
    "ax.set_ylabel(\"ImageNet top-1 error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dd458",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Deviation over depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9987b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Resolution vs. output (grid & QMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7a0b2ec8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_logits, grid_logits, grid_masks, qmc_logits, qmc_masks = torch.load(osp.expanduser(\n",
    "    '~/code/diffcoord/temp/change_resolution_grid_vs_qmc.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1700eb06",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_dists = (torch.cat(grid_logits, dim=0) - base_logits.cpu()).norm(dim=-1)\n",
    "qmc_dists = (torch.cat(qmc_logits, dim=0) - base_logits.cpu()).norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b48a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.sort(base_logits[0]).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74736508",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.sort(qmc_logits[-1][0]).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170b724",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.bar(grid_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a1e1de8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15575.2344,  1041.2139,   471.6435,   106.5965,    59.1255,    45.8519,\n",
       "           41.1897,    39.6904])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmc_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5b164d3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "front_g_m = torch.stack([m[0].float().mean() for m in grid_masks], dim=0)\n",
    "front_g_s = torch.stack([m[0].float().std() for m in grid_masks], dim=0)\n",
    "back_g_m = torch.stack([m[1].float().mean() for m in grid_masks], dim=0)\n",
    "back_g_s = torch.stack([m[1].float().std() for m in grid_masks], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5e2b3487",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.0000,  10.5625,   8.6289,  15.0156,  46.4102,  60.5479, 160.5764,\n",
       "         196.0000]),\n",
       " tensor([ 0.0000,  3.0957,  1.0093,  4.7626,  6.1273, 22.8689, 20.5887, 87.4629]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front_g_m, front_g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1768d76f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.0000,   2.2500,   7.5625,   7.5625,  39.0625,  31.6406, 136.5977,\n",
       "         142.5039]),\n",
       " tensor([ 0.0000,  1.1255,  1.7078,  1.7078,  9.7238,  6.8699, 33.1658, 35.0628]))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_g_m, back_g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e2170c8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "front_q_m = torch.stack([m[0].float().mean() for m in qmc_masks], dim=0)\n",
    "front_q_s = torch.stack([m[0].float().std() for m in qmc_masks], dim=0)\n",
    "back_q_m = torch.stack([m[1].float().mean() for m in qmc_masks], dim=0)\n",
    "back_q_s = torch.stack([m[1].float().std() for m in qmc_masks], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4b1a553c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.8906,   4.7576,   9.3281,  18.5356,  37.3281,  74.0309, 146.2527,\n",
       "         292.7811]),\n",
       " tensor([ 0.6695,  1.0991,  1.6431,  2.6684,  4.9519,  9.4219, 18.3863, 36.7924]))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front_q_m, front_q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6043303a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  3.2500,   4.6970,   8.4375,  15.3492,  31.3125,  63.8085, 126.1699,\n",
       "         250.4597]),\n",
       " tensor([ 1.3416,  1.3803,  2.1958,  3.7912,  7.4199, 15.3288, 30.1571, 59.7511]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_q_m, back_q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ee084",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a5237",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77dc80d8",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### RQMC variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bde36",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_logits, logits, masks = torch.load(osp.expanduser('~/code/diffcoord/temp/output_variance_rqmc.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "23a1681d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logit_dists = (torch.cat(logits, dim=0) - base_logits.cpu()).norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199adafd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logit_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc02758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fronts.mean(1), fronts.std(1), fronts.amin(1), fronts.amax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47499a68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backs.mean(1), backs.std(1), backs.amin(1), backs.amax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ab0422a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fronts = torch.stack([m[0] for m in masks], dim=0).float()\n",
    "backs = torch.stack([m[1] for m in masks], dim=0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a86d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a6da528",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### grid-QMC interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e00974",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_logits, grid_logits, grid_mask, qmc_logits, qmc_mask, intermediate_logits, intermediate_masks = torch.load(osp.expanduser('~/code/diffcoord/temp/analyze_logit_mismatch.pt'))\n",
    "\n",
    "x = np.arange(0,1.01,.05)\n",
    "fronts = torch.stack([grid_mask[0], *[m[0] for m in intermediate_masks[::-1]], qmc_mask[0]], dim=0).float()\n",
    "backs = torch.stack([grid_mask[1], *[m[1] for m in intermediate_masks[::-1]], qmc_mask[1]], dim=0).float()\n",
    "f_m, f_s = fronts.mean(1), fronts.std(1)\n",
    "b_m, b_s = backs.mean(1), backs.std(1)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "width = .007\n",
    "ax.errorbar(x-width/2, f_m, yerr=f_s, label='front')\n",
    "ax.errorbar(x+width/2, b_m, yerr=b_s, label='back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf6d9e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = (torch.cat([grid_logits, *intermediate_logits[::-1], qmc_logits], dim=0) - base_logits.cpu()).norm(dim=1)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d940a7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bda67bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "coco_len = 118287\n",
    "kitti_len = 80896\n",
    "horse_len = 1067\n",
    "zebra_len = 1334\n",
    "inet_len = 50000\n",
    "in_tr_len = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34845a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "configs/convnext/upernet_convnext_tiny\n",
    "configs/_base_/models/upernet_convnext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b6c75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,places_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/places/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"place{ix//800}\", \"fit_places\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae78790",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,in_tr_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/imagenet1k_train/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//800}\", \"fit_in_tr\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfddc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,60000,5000):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/fmnist/train_{ix+1}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"fmn{ix//5000}\", \"fit_fmnist\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b53ce",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,12000,100):\n",
    "    c,i=ix//1000, ix%1000\n",
    "    if i >= 800:\n",
    "        i-=800\n",
    "        s='val'\n",
    "    else:\n",
    "        s='train'\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/{c}/{s}_{i+3}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//100}\", \"fit_i12\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3064a197",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,2400,50):\n",
    "    c,i = ix%12, ix//12\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/{c}/test_{i+1}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"rff{ix//50}\", \"fit_in_rff\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595185c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#23400 * 12 = 280800 total images\n",
    "#15000/12 + 800 = 2050 current images per class\n",
    "for ix in range(36000,48000,100):\n",
    "    cls, start_ix = ix % 12, ix // 12 + 800\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/{cls}/train_{start_ix+4}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//100}\", \"fit_i12\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84027d",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,8189,100):\n",
    "    i = ix\n",
    "    if i < 1020:\n",
    "        s='train'\n",
    "    elif i < 2040:\n",
    "        s='val'\n",
    "        i -= 1020\n",
    "    else:\n",
    "        s='test'\n",
    "        i -= 2040\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/flowers/{s}_{i+50}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"flow{ix//100}\", \"fit_flower\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215c526",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(3475,4475,100):\n",
    "    i = ix\n",
    "    if i >= 2975:\n",
    "        i -= 2975\n",
    "        s = 'val'\n",
    "    else:\n",
    "        s = 'train'\n",
    "        i -= 500\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/cityscapes/{s}_{i+1}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"city{ix//100}\", \"fit_city\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13166e6f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,inet_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/imagenet1k_val/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"inet{ix//800}\", \"fit_inet\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faec908c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x[0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6b92f",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,coco_len,1600):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/coco/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"coco{ix//1600}\", \"fit_coco\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b852ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,kitti_len,800):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/kitti/siren_{ix+63}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"skit{ix//800}\", \"fit_kitti\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc286a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,zebra_len,128):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/zebra/siren_{ix+15}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"zebra{ix//128}\", \"fit_zebra\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004877cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,horse_len,128):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/horse/siren_{ix+15}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"horse{ix//128}\", \"fit_horse\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef320b86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,10000,5000):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/cifar10_test/siren_{ix+999}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"cit{ix//5000}\", \"fit_ciftest\", ix)\n",
    "for ix in range(0,50000,5000):\n",
    "    if not osp.exists(f\"/data/vision/polina/scratch/clintonw/datasets/inrnet/cifar10_train/siren_{ix+999}.pt\"):\n",
    "        print(\"sh fit_inr.sh\", f\"cif{ix//5000}\", \"fit_cifar\", ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4a6a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread(\"/data/vision/polina/scratch/clintonw/datasets/inrnet/horse2zebra/testA/n02381460_9260.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6392169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"/data/vision/polina/scratch/clintonw/datasets/coco/annotations/panoptic_train2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26693f19",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "osp.exists(f\"/data/vision/polina/users/clintonw/code/diffcoord/temp/kitti/siren_{ix+63}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "201b45c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paths = util.glob2(\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/1/loss_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86d162",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paths = util.glob2(\"/data/vision/polina/scratch/clintonw/datasets/inrnet/inet12/0/loss_train_10*\")\n",
    "for p in paths[10:100]:\n",
    "    print(open(p,'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1d40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
